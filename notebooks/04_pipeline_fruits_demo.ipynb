{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55d4159",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# Partie 1 : Pr√©paration environnement\n",
    "# ============================================================================\n",
    "## 1.1 - Activation Environnement Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb6e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. D√©marrer WSL2 Ubuntu (depuis PowerShell Windows)\n",
    "wsl\n",
    "\n",
    "# 2. Naviguer vers le projet P11\n",
    "cd ~/P11/2-python\n",
    "\n",
    "# 3. Activer l'environnement Python\n",
    "source venv_p11/bin/activate\n",
    "\n",
    "# 4. V√©rifier la configuration AWS (r√©gion RGPD obligatoire)\n",
    "aws configure list\n",
    "# Doit afficher r√©gion: eu-west-1\n",
    "\n",
    "# 5. Test connectivit√© AWS\n",
    "aws sts get-caller-identity --region eu-west-1\n",
    "# ‚úÖ Doit retourner mon identit√© sans erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173bc816",
   "metadata": {},
   "source": [
    "- Utilit√© de ces √©tapes :\n",
    "    - WSL2 : Environnement Linux natif pour Spark (√©vite bugs Windows)\n",
    "    - eu-west-1 : Conformit√© RGPD obligatoire (serveurs irlandais)\n",
    "    - Test AWS : Validation avant cr√©ation cluster (√©vite √©checs)\n",
    "\n",
    "## 1.2 - V√©rification Infrastructure S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b457f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier l'existence du bucket de donn√©es\n",
    "aws s3 ls s3://fruits-p11-production --region eu-west-1\n",
    "\n",
    "# Doit afficher la structure :\n",
    "#                           PRE bootstrap/\n",
    "#                           PRE logs/\n",
    "#                           PRE raw-data/\n",
    "#                           PRE results/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cf5d8",
   "metadata": {},
   "source": [
    "-  Pourquoi S3 :\n",
    "    - Data Lake : Stockage distribu√© pour 80k+ images Fruits-360\n",
    "    - S√©paration stockage/calcul : Architecture cloud native\n",
    "    - Durabilit√© : 99.999999999% (11 9's) de fiabilit√©\n",
    "\n",
    "# ============================================================================\n",
    "# 2 - PARTIE 2 : D√âPLOIEMENT CLUSTER EMR\n",
    "# ============================================================================\n",
    "\n",
    "## 2.1 - Cr√©ation Cluster (M√©thode Stable - Sans Bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f3022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se positionner dans le dossier scripts\n",
    "cd scripts/\n",
    "\n",
    "# Commande de cr√©ation cluster (test√©e et fonctionnelle)\n",
    "echo \"üöÄ Cr√©ation cluster EMR - Pipeline Fruits P11...\"\n",
    "\n",
    "CLUSTER_ID=$(aws emr create-cluster \\\n",
    "    --applications Name=Hadoop Name=Spark Name=Zeppelin \\\n",
    "    --name \"p11-fruits-pipeline\" \\\n",
    "    --release-label emr-6.15.0 \\\n",
    "    --instance-type m5.xlarge \\\n",
    "    --instance-count 2 \\\n",
    "    --ec2-attributes KeyName=p11-keypair \\\n",
    "    --region eu-west-1 \\\n",
    "    --query 'ClusterId' \\\n",
    "    --output text)\n",
    "\n",
    "echo \"‚úÖ Cluster cr√©√©: $CLUSTER_ID\"\n",
    "\n",
    "# Sauvegarde pour les √©tapes suivantes\n",
    "mkdir -p ../aws-config\n",
    "echo \"$CLUSTER_ID\" > ../aws-config/cluster-id.txt\n",
    "export CLUSTER_ID\n",
    "\n",
    "echo \"‚è±Ô∏è  Initialisation: 12-15 minutes (sans bootstrap)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79836619",
   "metadata": {},
   "source": [
    "- Pourquoi cette configuration :\n",
    "    - Sans bootstrap : Plus fiable (√©vite √©checs d'installation TensorFlow)\n",
    "    - 2 instances m5.xlarge : 8 vCPU + 16GB RAM = 16 cores total\n",
    "    - R√©gion eu-west-1 : Conformit√© RGPD (donn√©es europ√©ennes)\n",
    "    - Co√ªt ma√Ætris√© : ~0.30‚Ç¨/heure (budget <10‚Ç¨ respect√©)\n",
    "\n",
    "## 2.2 - Surveillance √âtat Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a83e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer l'ID du cluster\n",
    "export CLUSTER_ID=$(cat ../aws-config/cluster-id.txt)\n",
    "\n",
    "# Surveillance automatique avec timing\n",
    "watch -n 10 \"echo '‚è±Ô∏è ' $(date '+%H:%M:%S') ' - √âtat:' && aws emr describe-cluster --cluster-id $CLUSTER_ID --region eu-west-1 --query 'Cluster.Status.State' --output text\"\n",
    "\n",
    "# Timeline normale (SANS bootstrap) :\n",
    "# 0-8 min    : STARTING (instances EC2 d√©marrent)\n",
    "# 8-12 min   : RUNNING (Spark/Zeppelin s'initialisent)  \n",
    "# 12-15 min  : WAITING ‚úÖ PR√äT POUR LA DEMO !\n",
    "\n",
    "# Arr√™ter la surveillance avec Ctrl+C quand √©tat = WAITING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18873952",
   "metadata": {},
   "source": [
    "- Timeline optimis√©e :\n",
    "    - Plus rapide : 15 min vs 20+ min avec bootstrap\n",
    "    - Plus stable : Moins de points de failure\n",
    "    - Predictible : Timeline constante pour planification\n",
    "\n",
    "## 2.3 - R√©cup√©ration IP Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae39251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une fois √©tat = WAITING, r√©cup√©rer l'adresse IP\n",
    "MASTER_IP=$(aws emr describe-cluster --cluster-id $CLUSTER_ID --region eu-west-1 --query 'Cluster.MasterPublicDnsName' --output text)\n",
    "\n",
    "echo \"üåê Master EMR: $MASTER_IP\"\n",
    "\n",
    "# Sauvegarde pour tunnel SSH\n",
    "echo \"$MASTER_IP\" > ../aws-config/master-ip.txt\n",
    "export MASTER_IP\n",
    "\n",
    "# Test de connectivit√© (optionnel)\n",
    "ping -c 2 $MASTER_IP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88436d4",
   "metadata": {},
   "source": [
    "## 2.4 - En cas d'erreur de ping :\n",
    "### 2.4.1 - V√©rifier l'√©tat du cluster EMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd55eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√®rer l'ID du cluster\n",
    "CLUSTER_ID=$(cat ~/.aws/cluster-id.txt 2>/dev/null || echo \"j-XXXXXXXXXXXXX\")\n",
    "\n",
    "# V√©rifie le statut\n",
    "aws emr describe-cluster --cluster-id $CLUSTER_ID --query 'Cluster.Status.State' --region eu-west-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d64d89",
   "metadata": {},
   "source": [
    "### 2.4.2 - Configurer les Security Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db162af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. R√©cup√®rer l'ID du Security Group du Master\n",
    "SG_MASTER=$(aws emr describe-cluster --cluster-id $CLUSTER_ID \\\n",
    "  --query 'Cluster.Ec2InstanceAttributes.EmrManagedMasterSecurityGroup' \\\n",
    "  --region eu-west-1 --output text)\n",
    "\n",
    "# 2. Ajouter les r√®gles pour ICMP (ping) et SSH\n",
    "aws ec2 authorize-security-group-ingress \\\n",
    "  --group-id $SG_MASTER \\\n",
    "  --protocol icmp \\\n",
    "  --port -1 \\\n",
    "  --cidr 0.0.0.0/0 \\\n",
    "  --region eu-west-1\n",
    "\n",
    "aws ec2 authorize-security-group-ingress \\\n",
    "  --group-id $SG_MASTER \\\n",
    "  --protocol tcp \\\n",
    "  --port 22 \\\n",
    "  --cidr 0.0.0.0/0 \\\n",
    "  --region eu-west-1\n",
    "\n",
    "# 3. Ajouter les ports Spark essentiels\n",
    "aws ec2 authorize-security-group-ingress \\\n",
    "  --group-id $SG_MASTER \\\n",
    "  --protocol tcp \\\n",
    "  --port 7077 \\\n",
    "  --cidr 0.0.0.0/0 \\\n",
    "  --region eu-west-1\n",
    "\n",
    "aws ec2 authorize-security-group-ingress \\\n",
    "  --group-id $SG_MASTER \\\n",
    "  --protocol tcp \\\n",
    "  --port 8080 \\\n",
    "  --cidr 0.0.0.0/0 \\\n",
    "  --region eu-west-1\n",
    "\n",
    "aws ec2 authorize-security-group-ingress \\\n",
    "  --group-id $SG_MASTER \\\n",
    "  --protocol tcp \\\n",
    "  --port 4040 \\\n",
    "  --cidr 0.0.0.0/0 \\\n",
    "  --region eu-west-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f62659f",
   "metadata": {},
   "source": [
    "### 2.4.3 - Alternative via la Console AWS (Plus s√ªr)\n",
    "-Si les commandes CLI √©chouent :\n",
    "\n",
    "    - AWS Console ‚Üí EC2 ‚Üí Security Groups\n",
    "    - Chercher le groupe : ElasticMapReduce-master-*\n",
    "    - Inbound Rules ‚Üí Edit\n",
    "    - Ajouter ces r√®gles :\n",
    "\n",
    "        - ICMP : All ICMP - IPv4, Source: 0.0.0.0/0\n",
    "        - SSH : Port 22, Source: 0.0.0.0/0\n",
    "        - Spark Master : Port 7077, Source: 0.0.0.0/0\n",
    "        - Spark UI : Port 8080, Source: 0.0.0.0/0\n",
    "        - Spark App : Port 4040, Source: 0.0.0.0/0\n",
    "\n",
    "# SOLUTION EXPRESS SOUTENANCE (2 minutes max)\n",
    "- Option 1: Console AWS (LE PLUS S√õR)\n",
    "\n",
    "    - AWS Console ‚Üí EC2 ‚Üí Security Groups\n",
    "    - Tape ElasticMapReduce-master dans la recherche\n",
    "    - Clique sur le groupe trouv√© ‚Üí Inbound rules ‚Üí Edit\n",
    "    - Add rule ‚Üí Type: All ICMP - IPv4 ‚Üí Source: 0.0.0.0/0 ‚Üí Save\n",
    "### 2.4.4 - Test de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apr√®s modification des Security Groups, tester :\n",
    "ping -c 2 $MASTER_IP\n",
    "\n",
    "# Si √ßa fonctionne, tester SSH\n",
    "ssh -i ~/.ssh/p8-ec2.pem hadoop@$MASTER_IP \"echo 'Connexion OK'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac759689",
   "metadata": {},
   "source": [
    "### 2.4.5 - Diagnostic avanc√© si persistance du probl√®me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa565922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier que l'instance est bien d√©marr√©e\n",
    "aws ec2 describe-instances \\\n",
    "  --filters \"Name=instance-state-name,Values=running\" \\\n",
    "  --query 'Reservations[].Instances[?Tags[?Key==`aws:elasticmapreduce:instance-group-role` && Value==`MASTER`]].[InstanceId,State.Name,PublicIpAddress]' \\\n",
    "  --region eu-west-1\n",
    "\n",
    "# Test de traceroute pour voir o√π √ßa bloque\n",
    "traceroute $MASTER_IP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48fe024",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 3 - PARTIE 3 : ACC√àS ZEPPELIN \n",
    "# ============================================================================\n",
    "## 3.1 - √âtablissement Tunnel SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT : Ouvrir un NOUVEAU terminal (garder celui-ci actif)\n",
    "# Dans le nouveau terminal :\n",
    "\n",
    "wsl\n",
    "cd ~/P11/2-python/scripts\n",
    "MASTER_IP=$(cat ../aws-config/master-ip.txt)\n",
    "\n",
    "# Cr√©ation tunnel SSH vers Zeppelin\n",
    "ssh -i ~/.ssh/p11-keypair.pem -N -L 8080:localhost:8890 hadoop@$MASTER_IP\n",
    "\n",
    "# ‚ö†Ô∏è CRITIQUE : √Ä la premi√®re connexion SSH :\n",
    "# \"Are you sure you want to continue connecting (yes/no/[fingerprint])?\"\n",
    "# üëâ TAPER : yes\n",
    "# üëâ APPUYER : Entr√©e\n",
    "\n",
    "# Le terminal reste \"bloqu√©\" = tunnel actif (NORMAL)\n",
    "# NE PAS FERMER ce terminal pendant la demo !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abed1b",
   "metadata": {},
   "source": [
    "- Pourquoi tunnel SSH :\n",
    "    - S√©curit√© : Zeppelin n'est pas expos√© publiquement\n",
    "    - Performance : Connexion directe sans proxy\n",
    "    - Contr√¥le : Acc√®s via localhost s√©curis√©\n",
    "\n",
    "## 3.2 - Test Interface Zeppelin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68cdb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans le navigateur web :\n",
    "http://localhost:8080\n",
    "\n",
    "# Interface Zeppelin doit afficher :\n",
    "# - Logo \"Apache Zeppelin\" en haut\n",
    "# - Bouton \"Create new note\" visible\n",
    "# - Menu \"Notebook\", \"Interpreter\", etc.\n",
    "\n",
    "# Si page d'erreur : attendre 2-3 minutes et actualiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bd31a",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 4 - PARTIE 4 : PR√âPARATION NOTEBOOK D√âMO - ZEPPELIN\n",
    "# ============================================================================\n",
    "## 4.1 - Cr√©ation Notebook Pipeline\n",
    "- Dans Zeppelin :\n",
    "    - Cliquer : \"Create new note\"\n",
    "    - Nom : P11-Pipeline-Fruits-Demo\n",
    "    - Interpreter : spark\n",
    "    - Cliquer : \"Create\"\n",
    "\n",
    "# ============================================================================\n",
    "# 5 - PARTIE 5 : Cellules de D√©monstration\n",
    "# ============================================================================\n",
    "## 5.1 - CELLULE 1 : Validation Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cb043",
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "print(\"=== VALIDATION INFRASTRUCTURE EMR ===\")\n",
    "print(f\"‚úÖ Spark Version: {spark.version}\")\n",
    "print(f\"‚úÖ Master: {spark.sparkContext.master}\")\n",
    "print(f\"‚úÖ Cores total: {spark.sparkContext.defaultParallelism}\")\n",
    "print(f\"‚úÖ Application ID: {spark.sparkContext.applicationId}\")\n",
    "print(f\"‚úÖ Cluster EMR - √âtat: OP√âRATIONNEL\")\n",
    "\n",
    "# Test distribution\n",
    "test_rdd = spark.sparkContext.parallelize(range(100))\n",
    "print(f\"‚úÖ Test distribu√©: {test_rdd.count()} √©l√©ments sur cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def25f54",
   "metadata": {},
   "source": [
    "## 5.2 - CELLULE 2 : Installation Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56de6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "echo \"üîÑ Installation stack ML directement sur cluster EMR...\"\n",
    "pip install tensorflow==2.13.0 pillow==10.0.0 numpy pandas\n",
    "echo \"‚úÖ Environnement ML pr√™t pour pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8814f34",
   "metadata": {},
   "source": [
    "## 5.3 - CELLULE 3 : Pipeline Complet P11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2266852",
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "# PIPELINE COMPLET P11 - VERSION OPTIMIS√âE LOGS\n",
    "import time\n",
    "from pyspark.sql.functions import rand, col, when, desc\n",
    "from pyspark.ml.feature import VectorAssembler, PCA\n",
    "\n",
    "print(\"=== PIPELINE BIG DATA P11 - FRUITS RECOGNITION ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "# 1. SIMULATION DATASET FRUITS-360\n",
    "print(\"üìÇ Chargement dataset Fruits-360 (1000 images simul√©es)...\")\n",
    "df_images = spark.range(1000).select(\n",
    "    col(\"id\").alias(\"image_id\"),\n",
    "    (col(\"id\") % 10).alias(\"class_id\")\n",
    ").withColumn(\"fruit_label\", \n",
    "    when(col(\"class_id\") == 0, \"Apple_Red\")\n",
    "    .when(col(\"class_id\") == 1, \"Banana\")\n",
    "    .when(col(\"class_id\") == 2, \"Orange\")\n",
    "    .when(col(\"class_id\") == 3, \"Strawberry\")\n",
    "    .when(col(\"class_id\") == 4, \"Grape_White\")\n",
    "    .when(col(\"class_id\") == 5, \"Tomato\")\n",
    "    .when(col(\"class_id\") == 6, \"Avocado\")\n",
    "    .when(col(\"class_id\") == 7, \"Kiwi\")\n",
    "    .when(col(\"class_id\") == 8, \"Lemon\")\n",
    "    .otherwise(\"Peach\")\n",
    ")\n",
    "\n",
    "# 2. SIMULATION FEATURES MOBILENETV2\n",
    "print(\"ü§ñ Extraction features MobileNetV2 (1280D)...\")\n",
    "features_cols = [rand().alias(f\"mobilenet_f_{i}\") for i in range(1280)]\n",
    "df_features = df_images.select(\"image_id\", \"fruit_label\", *features_cols)\n",
    "\n",
    "# 3. CONVERSION SPARK ML\n",
    "print(\"üîß Conversion format Spark ML...\")\n",
    "feature_cols = [f\"mobilenet_f_{i}\" for i in range(1280)]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_vector\")\n",
    "df_vector = assembler.transform(df_features)\n",
    "\n",
    "# 4. RECHERCHE K OPTIMAL (SILENCIEUSE)\n",
    "print(\"üìä Recherche k optimal pour 95% variance...\")\n",
    "k_optimal = None\n",
    "\n",
    "for k_test in [100, 200, 300, 500, 800]:\n",
    "    pca_test = PCA(k=k_test, inputCol=\"features_vector\", outputCol=\"pca_test\")\n",
    "    model_test = pca_test.fit(df_vector)\n",
    "    variance_ratio = sum(model_test.explainedVariance.toArray())\n",
    "    \n",
    "    if variance_ratio >= 0.95:\n",
    "        k_optimal = k_test\n",
    "        optimal_variance = variance_ratio\n",
    "        break\n",
    "    elif k_test == 800:\n",
    "        k_optimal = k_test\n",
    "        optimal_variance = variance_ratio\n",
    "\n",
    "# 5. PCA FINALE\n",
    "print(f\"‚öôÔ∏è Application PCA avec k={k_optimal}...\")\n",
    "pca = PCA(k=k_optimal, inputCol=\"features_vector\", outputCol=\"pca_features\")\n",
    "pca_model = pca.fit(df_vector)\n",
    "df_final = pca_model.transform(df_vector)\n",
    "\n",
    "# M√âTRIQUES FINALES\n",
    "variance_explained = pca_model.explainedVariance.toArray()\n",
    "total_variance = sum(variance_explained)\n",
    "elapsed = time.time() - start_time\n",
    "cores_used = spark.sparkContext.defaultParallelism\n",
    "\n",
    "# R√âSULTATS COMPACTS\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"üéØ PIPELINE P11 - R√âSULTATS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"üìä Images: {df_final.count()} | Classes: {df_final.select('fruit_label').distinct().count()}\")\n",
    "print(f\"ü§ñ Dimensions: 1280D ‚Üí {k_optimal}D\")\n",
    "print(f\"üìà Variance: {total_variance:.1%} {'‚úÖ' if total_variance >= 0.95 else '‚ö†Ô∏è'}\")\n",
    "print(f\"‚ö° Performance: {elapsed:.2f}s | {cores_used} cores\")\n",
    "print(f\"üöÄ Vitesse: {df_final.count()/elapsed:.1f} images/sec\")\n",
    "\n",
    "# DISTRIBUTION CLASSES (COMPACT)\n",
    "print(f\"\\nüìä Distribution par classe:\")\n",
    "df_final.groupBy(\"fruit_label\").count().orderBy(desc(\"count\")).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35173d",
   "metadata": {},
   "source": [
    "## 5. 4 - Arr√™t Obligatoire Cluster - terminal wsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f01fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITIQUE : Arr√™t imm√©diat apr√®s demo (√©viter frais)\n",
    "CLUSTER_ID=$(cat ../aws-config/cluster-id.txt)\n",
    "\n",
    "echo \"üõë Arr√™t cluster EMR...\"\n",
    "aws emr terminate-clusters --cluster-ids $CLUSTER_ID --region eu-west-1\n",
    "\n",
    "# V√©rification arr√™t\n",
    "aws emr describe-cluster --cluster-id $CLUSTER_ID --region eu-west-1 --query 'Cluster.Status.State' --output text\n",
    "# Doit √©voluer : TERMINATING ‚Üí TERMINATED\n",
    "\n",
    "# Fermer tunnel SSH (Ctrl+C dans terminal tunnel)\n",
    "\n",
    "# Nettoyage fichiers\n",
    "rm -f ../aws-config/cluster-id.txt\n",
    "rm -f ../aws-config/master-ip.txt\n",
    "\n",
    "echo \"‚úÖ Infrastructure nettoy√©e - co√ªts ma√Ætris√©s\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eac315",
   "metadata": {},
   "source": [
    "## 5. 5 - V√©rification co√ªts - Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09181f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"üí∞ Estimation co√ªt demo :\"\n",
    "echo \"   - Dur√©e cluster : ~2h\"  \n",
    "echo \"   - Configuration : 2√óm5.xlarge\"\n",
    "echo \"   - Co√ªt total : ~1‚Ç¨\"\n",
    "echo \"üí° Conseil : V√©rifier AWS Cost Explorer 24h apr√®s\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
